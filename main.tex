\documentclass{sig-alternate}

%Nice code listings
\usepackage{minted}
\usepackage[hidelinks]{hyperref}
\usepackage{url}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}

%Patch problems with sig-alternate template
%See: http://tex.stackexchange.com/questions/87891/typewriter-text-in-sections-with-acm-sig-alternate-document-class 
\DeclareRobustCommand{\ttfamily}{\fontencoding{T1}\fontfamily{lmtt}\selectfont}
\DeclareRobustCommand\sectt[1]{{\fontsize{13}{12}\bfseries\ttfamily#1}}

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{HPTCDL}{'14 New Orleans, Louisiana USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Operator polymorphism for distributed computing in Julia}

\numberofauthors{2}

\author{
% 1st. author
\alignauthor
Jiahao Chen\\
       \affaddr{Massachusetts Institute of Technology}\\
       \affaddr{Computer Science and Artificial Intelligence Laboratory}\\
       \affaddr{77 Massachusetts Avenue}\\
       \affaddr{Cambridge, Massachusetts 02139, USA}\\
       \email{jiahao@mit.edu}\\
% 2nd. author
\alignauthor
Alan Edelman\\
       \affaddr{Massachusetts Institute of Technology}\\
       \affaddr{Department of Mathematics and Computer Science and Artificial Intelligence Laboratory}\\
       \affaddr{77 Massachusetts Avenue}\\
       \affaddr{Cambridge, Massachusetts 02139, USA}\\
       \email{edelman@mit.edu}
}

\date{15 October 2014}

\maketitle
\begin{abstract}
High level languages provide nice abstractions for most computing tasks, but fall short of providing useful abstractions for parallel computing.

The lack of useful abstractions poses significant challenges for users of parallel computing.

In this paper we study a primitive parallel algorithm, namely that of prefix reduction, and show how it can be implemented with operator overloading so that the parallelism occurs at the operational level, not the algorithmic level.

The ability to write such code shows that Julia's abstractions are useful for reasoning about the structure of parallel algorithms by successfully abstracting away implementation details.

Code reuse for other tasks as well like visualization.

\end{abstract}

\category{D.1.3}{Concurrent programming}{Distributed programming}
\category{D.3.2}{Programming languages}{Very high-level languages}
\category{G.1.0}{General numerical analysis}{Parallel algorithms}

\terms{Algorithms}

\keywords{Julia, prefix sum, scan}

\section{Introduction}
Nobody really understands how to do parallel computing. In practice, a lot of parallel computing code is mucky and gross because you have to embed all sorts of low level MPI initialization and communication primitives in your code.

How do the GPU Gems chapter showcase parallel prefix?

Can we do better to abstract away the low level communication protocols of a distributed algorithm?

In Julia we expose how overloading at the operator level parallelism can be used to showcase the essentials of what is going on while relegating the parallelism to a lower more primitive level. In other words, successful abstraction!

\section{The Julia language}

Julia is a very high level dynamic language designed specifically for technical computing~\cite{Bezanson2012}.

Type system and multiple dispatch. The type system is a resource for programmers, not just a low level compiler system that is hidden from the user. Being able to use types in user written code has turned out to be a great boon for writing technical code.

Polymorphism. Julia provides two distinct kinds of polymorphism. One is the paradigm of multimethods and the other is parametric polymorphism. We will focus more on how multimethods are helpful.

\section{The prefix reduction algorithm}
\label{sec:prefix}

What is prefix reduction~\cite{Iverson1962,Ladner1980,Brent1982}? Making use of associativity (or approximate associativity side node about floating point and how it doesn't really matter for most applications)  to regroup operations to provide different execution strategies.

Parallel scan is one of the ur-algorithms for parallel computing~\cite{Kruskal1985,Blelloch1989,Bell2012}.
There are many applications for the basic prefix sum algorithm~\cite{Blelloch1990,Blelloch1993}, but to just name a few relevant for technical computing, we can do 

\begin{itemize}

	\item stream compaction~\cite{Harris2007}

	\item parallel sort~\cite{Blelloch1989}

	\item polynomial interpolation~\cite{Egecioglu1990}

	\item list operations~\cite{Hillis1986,Gorlatch1999}

	\item solving linear systems of equations involving block tridiagonal matrices~\cite{Mathias1995}

	\item minimal coverings of black-and-white images~\cite{Moitra1991}

	\item string matching problems~\cite{Chi1992}

	\item random number generation~\cite{Lu1996}

	\item simulating finite state machines~\cite{Ladner1980}
\end{itemize}

The prefix sum problem, in its most basic form, is to compute from some initial
data \code{y} the cumulative partial sums \code{z} such that:

\begin{minted}{julia}
z[1] = y[1]
z[2] = y[1] + y[2]
z[3] = y[1] + y[2] + y[3]
...
\end{minted}

The obvious algorithm to compute the cumulative sums is the left-associative
algorithm \code{prefix\allowbreak\_serial!}:

\begin{minted}{julia}
function prefix_serial!(y, +)
    @inbounds for i=2:length(y)
        y[i] = y[i-1] + y[i]
    end
    y
end
\end{minted}

The bang \code{!} at the end of the function name is a Julia convention
denoting that the function mutates at least one of its arguments (in this case,
\code{y}). At each iteration of the \code{for} loop, the partial result from
the previous iteration is added on, or prefixed, onto the computation for the
current iterate. The recurrence generated by prefixing generalizes naturally to
other associative operators besides \code{+}; in fact, Julia allows us to
specify the scan as a higher-order function, simply by specifying both the data
\code{y} and an arbitrary associative operator \code{+} as inputs to the
\code{prefix\allowbreak\_serial!} function.~\cite{Shah2013} Passing in an argument named
\code{+} allows us to generalize the prefix sum transparently to any
associative binary operator within the scope of the function body, while
keeping the infix syntax for \code{+}.

As written, the \code{prefix\allowbreak\_serial!} function assumes, but does not check,
that the function passed to it is associative. If necessary, checks of the form

\mint{julia}|@assert (y[1]+y[2])+y[3]==y[1]+(y[2]+y[3])|

can be included, but for simplicity of presentation, we omit such checks from
the code presented in this paper. We also neglect concerns relating to
\textit{approximate} associativity, such as roundoff errors in floating-point
addition or multiplication~\cite{Mathias1995}.

Parallel prefix algorithms for implementing the scan function take advantage of
associativity by regrouping the operations into tree structures. One of the
simplest to understand is known as the Brent--Kung form~\cite{Brent1982}, where
the computation is organized into two trees. For simplicity, we present first
the special case of parallel prefix for $n=8$ data points.

\begin{minted}{julia}
function prefix8!(y, +)
    length(y)==8 || error("length 8 only")
    for i in [2,4,6,8] y[i] = y[i-1] + y[i] end
    for i in [  4,  8] y[i] = y[i-2] + y[i] end
    for i in [      8] y[i] = y[i-4] + y[i] end
    for i in [    6  ] y[i] = y[i-2] + y[i] end
    for i in [ 3,5,7 ] y[i] = y[i-1] + y[i] end
    y
end
\end{minted}

Figure~\ref{fig:gates} illustrates the difference between the number and order
of operations in \code{prefix\allowbreak\_serial!} and \code{prefix8!}. Each vertical line
represents a processor \code{i} operating on the data \code{y[i]}. Each
operation of the form \code{y[i] = y[j] + y[i]} is represented by a gate with
inputs on lines \code{i} and \code{j} and a single output on line \code{i}. The
main idea is that even though it takes more operations to organizing the
computation in the double tree form of \code{prefix8!}, it is possible to
execute each stage of the computation tree concurrently, and parallel speedup
can be achieved if the depth of the resulting tree is shorter than the depth of
the tree for the serial algorithm. Nevertheless, at this point we have not
actually computed anything in parallel, merely organized the computation in a
way that would \textit{allow} for concurrent execution. Running the code as is
on an \code{Array} object would run the operations sequentially, from left to
right, then top to bottom of the computation tree. 
\begin{figure}
  \centering

  \mint{julia}|render(prefix_serial!(AccessArray(8),+))|
  \includegraphics{serial}
  \vspace{12 pt}
  \mint{julia}|render(prefix8!(AccessArray(8),+))|
  \includegraphics{tree}
  \caption{Above: operation order for the left-associative algorithm \code{prefix\allowbreak\_serial!}.
           Below: operation order for the tree algorithm \code{prefix8!}.
           The code listing for the \code{render} function is given in Section~\ref{sec:render}.  This figure was rendered in Compose, a Julia package for declarative vector graphics~\cite{Compose.jl}.}
  \label{fig:gates}
\end{figure}

To conclude our exposition of the scan problem, we present the \code{prefix!}
function that solves the general case of $n$ data points. While the indices are
somewhat less clear than when explicitly written out in \code{prefix8!},
\code{prefix!} function nonetheless preserves the double tree structure.

\begin{minted}{julia}
function prefix!(y, .+)
    l=length(y)
    k=iceil(log2(l))
    #The "reduce" tree
    @inbounds for j=1:k, i=2^j:2^j:min(l, 2^k)
        y[i] = y[i-2^(j-1)] .+ y[i]
    end
    #The "broadcast" tree
    @inbounds for j=(k-1):-1:1, i=3*2^(j-1):2^j:
            min(l, 2^k)
        y[i] = y[i-2^(j-1)] .+ y[i]
    end
    y
end
\end{minted}

Again, at this point we have only written serial code that introduces more
computations than the naive algorithm \code{prefix\allowbreak\_serial!}. However, we will
argue in Section~\ref{sec:parallel-prefix} that the exact same code in
\code{prefix!} can be reused for parallel execution which can achieve speedup
over \code{prefix\allowbreak\_serial!}.

\section{Distributed computing using prefix reduction}

In this section we show how the prefix algorithm we wrote above can be run in a
distributed computing context without modification. The key is to make use of
overloading using the multimethod dispatch feature of Julia.

Julia provides native support for multiprocess distributed computing based on
one-sided message passing. The basic functionality is provided by the
\code{remotecall} function, which initiates a nonblocking remote function call
and returns an explicit future (a remote pointer of type \code{RemoteRef})
whose value is retrieved by the \code{fetch} function, which is a blocking
operation. Julia also provides more convenient syntax for \code{remotecall}
with the \code{@spawn} and \code{@spawnat} macros, which automatically rewrite
Julia expressions into \code{remotecall} function calls.

We can use Julia's multiple dispatch feature to define associative operators
which act on remote data rather than local data. Julia's generic function
system allows new methods which act on remote data to be defined for functions
like \code{+} and \code{*}, which are simply functions for which the parser
supports infix notation. In effect, we can overload addition and multiplication
(or in general any binary associative function) transparently to work on remote
data.

For example, we can run the following code:

\begin{minted}{julia}
#Start a Julia process on every available core
#addprocs(n) adds n processors
#Sys.CPU_CORES is the total number of available
#CPU cores
#nprocs() returns the total number of Julia
#processes attached to the current master
#(including itself)
addprocs(max(0, Sys.CPU_CORES-nprocs()))

import Base.* #Extend existing generic function

#Define elementary operations on remote data
*(r1::RemoteRef,r2::RemoteRef)=
    @spawnat r2.where fetch(r1)*fetch(r2)
\end{minted}

This one method definition defines multiplication on remote data by
\code{fetch}ing the remote data from the process containing the data of
\code{r1}, copying the data of \code{fetch(r1)} to the memory space of the
process containing the data of \code{r2} whose identity is given by
\code{r2.where}. The process \code{r2.where} now contains local copies of both
operands. Assuming that the local data are of type \code{T}, the Julia code
then invokes another round of method dispatch based on the method signature
\code{*(::T, ::T)}. In this way, any data type \code{T} that supports
multiplication will now also support remote multiplication, regardless of
whether the data are scalar numbers, $N\times N$ matrices, or something else
entirely.

The main point of this paper is that the very same function \code{prefix!}
which was executed in serial in previous sections will now run in parallel,
simply by passing to it an associative operator over remote data rather than
local data. Julia's multimethods and multiple dispatch semantics allow
operations on remote data to share the same syntax as their corresponding
operations on local data, thus removing any syntactic difference between remote
and local operations. The new method for \code{*} defines new behavior
specific to \code{RemoteRef}s, which are Julia's explicit futures. With this
new method defined in the current scope, running \code{prefix!(y, *)} will
automatically compute cumulative products on remote data if \code{y} is an
array of \code{RemoteRef}s. Julia will automatically dispatch on the
\code{*(r1::RemoteRef, r2::RemoteRef)} method within the inner loops of
\code{prefix!} by comparing the types of the data elements of \code{y} with
method signatures defined for \code{*}.

\subsection{Parallel prefix}
\label{sec:parallel-prefix}

We now run the \code{prefix!} function in parallel. The remote operations
\code{*(r1::RemoteRef, r2::RemoteRef)} contain blocking operations implied by
\code{fetch(r1)}, and Julia dynamically schedules all remote operations
simultaneously so long as they are not waiting on the result of a \code{fetch}
operation. The scheduling and dependency structure of \code{prefix!} thus
results in all operations in each stage of the tree being executed
simultaneously. Neglecting overhead from communication latency and bandwidth,
the total execution time of \code{prefix!} depends only on the depth of the
trees defined by the inner loops of \code{prefix!} and visualized in
Figure~\ref{fig:gates}.

From the indices of each loop in \code{prefix!} for $l$ data points, the first
tree has at least one operation at depth $k$ for $l \ge 2^k$, and therefore the
depth of the entire tree is $k = \floor{\log_2 l}$. Similarly, the second tree
has at least one operation at depth $k$ for $l \ge 3\cdot2^{k-1}$, and hence
has depth $k = 1 + \floor{log_2 \frac l 3}$. Adding these depths and assuming
that we distribute one datum per processor, we therefore obtain the theoretical
speedup ratio for $p$ processors running \code{prefix!} over
\code{prefix\allowbreak\_serial!} as:

\begin{equation}
    r (p) = \frac {p-1} {\floor{\log_2 p} + 1 + \floor{\log_2 \frac p 3}}.
    \label{eq:scaling-theory}
\end{equation}

Figure~\ref{fig:scaling} summarizing benchmark timings for a sample problem
where we generated $p$ square random matrices with Gaussian entries of size $n
= 4096$ and timed how long it took to multiply these matrices together.  We
specifically left out the time needed to broadcast the data to the remote
processes, so as to focus only on the execution times of the kernels of
interest. We also took care to disable the garbage collector. Julia, like many
high-level dynamic languages, provides a garbage collector to aid in memory
management. Julia 0.3.1 uses a simple stop-the-world, non-moving, precise mark
and sweep garbage collector, where deallocation and finalization of garbage
objects may not happen immediately after objects become unused\footnote{The
code for Julia's garbage collector may be found at
\url{https://github.com/JuliaLang/julia/blob/275afc8b74b9c6ea5d34aefb8085525ff5dfc239/src/gc.c}}~\cite{McCarthy1960}.
Therefore, it becomes important to factor out the possible effects of
stop-the-world garbage collection. We explicitly disabled garbage collection
with \code{gc\_disable()} before running each kernel, then reenabled garbage
collection with \code{gc\_enable()} after running each kernel. As an additional
precaution, we timed the kernels multiple times and took the minimum time for
each kernel so as to reduce fluctuations due to general nondeterministic
delays.

\begin{figure}
  \centering
  \includegraphics{scaling}
  \caption{Weak scaling of the prefix sum kernels. Speedup ratios are the
  timings for \code{prefix!} over \code{prefix\allowbreak\_serial!}. Plotted as a solid
  line is the theoretical speedup ratio $r(p)$ of
  Equation~\ref{eq:scaling-theory}.  This figure was rendered in Gadfly, a
  Julia package for native plotting and
  visualization~\cite{Gadfly.jl}.}
  \label{fig:scaling}
\end{figure}

The empirical timings shown in Figure~\ref{fig:scaling} show excellent
agreement with the theoretical prediction of Equation~\ref{eq:scaling-theory}.

\subsection{Operator overloading for visualization}

We can use the code above to use useful computations but we can also visualize its execution!

We make use of the fact that Julia's arrays provide indexing semantics which can be overloaded for custom types~\cite{Bezanson2014}.

We note that code of the form

\begin{minted}{julia}
a[i] = a[j] + a[k]}
\end{minted}
is desugared into syntax of the form

\begin{minted}{julia}
x = getindex(a, j)
y = getindex(a, k)
z = x+y
setindex!(a, z, i)
\end{minted}

There are much more complicated indexing behaviors but we will not touch on them here~\cite{Bezanson2014}.

The nice thing is you can write a custom type that implements \code{getindex} and \code{setindex!}. You don't have to go crazy and implement ALL the indexing semantics of Julia arrays, just the methods that are relevant to your specific application. In this problem all that is really needed is the indexing semantics of a single element.

Now all we have to do is to introduce a custom type that doesn't really do anything but instead records every \code{getindex} and \code{setindex!} operation performed on it. To satisfy the minimum requirements of the prefix reduction algorithm all we need at the moment is for \code{getindex} to return \code{nothing} and to define a dummy method for the associative operator \code{+} that operates on \code{nothing}. \code{nothing} is a value of the special singleton type \code{Void}, akin to Python's \code{none} or Haskell's \code{Nothing}.

Here is a code listing of implementing the trace type

\begin{minted}{julia}
import Base: getindex, setindex!, length

type AccessArray
    length :: Int
    read :: Vector
    history :: Vector
    AccessArray(length)=new(length, {}, {})
end

length(A::AccessArray)=A.length

function getindex(A::AccessArray, i)
    push!(A.read, i)
    nothing
end

function setindex!(A::AccessArray, x, i)
    push!(A.history, (A.read, {i}))
    A.read = {}
end
\end{minted}

\section{Proving correctness}

In Section~\ref{sec:prefix} we introduced several different kernels to compute
scans. Each of these kernels have exactly the same function signature \code{(y,
+)} representing the data \code{y} and associative binary operator \code{+}.
These two ingredients for the scan algorithm turn out to have exactly the
algebraic structure of a monoid.

Recent theoretical work has taken advantage of the monoidal structure. First,
the monoidal structure has been used to construct a formal algebra of scan
algorithms to understand the computational equivalence between many different
execution trees.~\cite{Hinze2004} More recent work has taken advantage of the
monoidal structure to show that correctness can be established simply by
showing that a given prefix sum kernel is correct for one particular monoid,
called the interval of summations monoid, on one specific input set.~\cite{Chong2014}

With Julia's polymorphism this is pretty trivial to implement!

\section{Related work}

What do other languages do?

Other languages also provide scan primitives like APL~\cite{Iverson1962}, ZPL~\cite{Chamberlain2000}.

MPI provides the \code{MPI\_scan} primitive~\cite{Snir1995,MPI}, and in MPI-2, also the \code{MPI\_Exscan} primitive for exclusive scan.~\cite{MPI2}

Other approaches wish they have genericity, like the Thrust C++ library which uses crazy C++ functors~\cite{Bell2012}.

Does Haskell have something using monoids?

Haskell Accelerate for GPU programming~\cite{Chakravarty2011}. Is it generic? Yes because it works at the code generation level, taking in expressions and emitting longer expressions that compute the prefix sum. In Haskell land these things are criticised for being not statically typed...?

In Julia we use duck typing.

Our approach is rather naive and does not account for the complexities in real world implementations, for example possible synchronicity issues produced by higher levels of the broadcast and reduce trees that could result in bus saturation. In principle this can be handled at the scheduler level in the system but we currently don't have the capabilities to do so in Julia.

\section{Conclusions and outlook}

Here is a way to visualize parallel algorithms and study their correctness. First we show that with pure operator polymorphism we can explicitly show the equivalence of a parallel algorithm and a sequential execution that accomplishes the same computations. This can be used to prove the correctness of a parallel algorithm.

Other variants: e.g. Snir~\cite{Kruskal1985}, Koc~\cite{Egecioglu1992}, doubly pipelined~\cite{Sanders2006}, harmonically scheduled~\cite{Wang1996}, segmented scan~\cite{Sengupta2007}.

Generalization to nonassocative binary operations~\cite{Chen1992}

Visualization is a byproduct of a correct algorithm. This is a powerful new way to understand how algorithms work.

How about something about fast multipole and variants?

\section{Acknowledgments}
We gratefully acknowledge the Julia community, especially Jake Bolewski, for insightful discussions.

Also funding.

\bibliographystyle{abbrv}
\bibliography{prefix}

\appendix

\section{The \code{render} function}
\label{sec:render}

Here are the \code{gate} type and \code{render} function used to generate the figures in Figure~\ref{fig:gates}.

\begin{minted}{julia}
using Compose

type gate
    ins :: Vector
    outs:: Vector
end

function render(G::gate, x, y, y0; ri=0.1, ro=0.25)
    ipoints = [(i, y0+ri) for i in G.ins]
    opoints = [(i, y0+0.5) for i in G.outs]
    igates  = [circle(i..., ri) for i in ipoints]
    ogates  = [circle(i..., ro) for i in opoints]
    lines = [line([i, j]) for i in ipoints,
                              j in opoints]

    compose(context(units=UnitBox(0.5, 0, x, y+1)),
        compose(context(), stroke("black"),
	    fill("white"), igates..., ogates...),
        compose(context(), linewidth(0.3mm),
	    stroke("black"), lines...))
end

function render(A::AccessArray)
    #Scan to find maximum depth
    olast = depth = 0
    for y in A.history
        (any(y[1] .<= olast)) && (depth += 1)
        olast = maximum(y[2])
    end
    maxdepth = depth
    
    olast = depth = 0
    C = {}
    for y in A.history
        (any(y[1] .<= olast)) && (depth += 1)
        push!(C, render(gate(y...), A.length,
	    maxdepth, depth))
        olast = maximum(y[2])
    end
    
    push!(C, compose(context(
      units=UnitBox(0.5, 0, A.length, 1)),
      [line([(i,0), (i,1)]) for i=1:A.length]...,
      linewidth(0.1mm), stroke("grey")))
    compose(context(), C...)
end
\end{minted}

\end{document}
